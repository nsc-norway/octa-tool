{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to simulate the index mis-assignment encountered in sequencing, and validate the formulae used in the main program against the simulation truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index example\n",
    "These indexes have been used for a project at the NSC facility (just an example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index1s = split(\"\"\"CTCGACTT CGAAGTAT TAGCAGCT TCTCTATG GATCTACG GTAACGAG ACGTGCGC ATAGTACC GCGTATAC AACGCTGA CGTAGCGA CTCGACTT TAGCAGCT TCTCTATG GATCTACG GTAACGAG ACGTGCGC ATAGTACC GCGTATAC TGCTCGTA AACGCTGA CGTAGCGA CTCGACTT CGAAGTAT TAGCAGCT TCTCTATG ACGTGCGC ATAGTACC GCGTATAC TGCTCGTA CGTAGCGA CTCGACTT TAGCAGCT TCTCTATG GATCTACG GTAACGAG ACGTGCGC ATAGTACC GCGTATAC TGCTCGTA AACGCTGA CGTAGCGA CTCGACTT TAGCAGCT GATCTACG GTAACGAG ATAGTACC GCGTATAC TGCTCGTA AACGCTGA CGTAGCGA CTCGACTT CGAAGTAT TCTCTATG GATCTACG GTAACGAG ACGTGCGC ATAGTACC GCGTATAC TGCTCGTA CGTAGCGA CTCGACTT CGAAGTAT TAGCAGCT TCTCTATG GATCTACG GTAACGAG ATAGTACC GCGTATAC TGCTCGTA AACGCTGA CGTAGCGA CTCGACTT CGAAGTAT TAGCAGCT TCTCTATG GATCTACG GTAACGAG CGTAGCGA CGAGAGTT GACATAGT ACGCTACT ACTCACTG TGAGTACG CTGCGTAG TAGTCTCC CGAGCGAC ACTACGAC GTCTGCTA GTCTATGA TATAGCGA CGAGAGTT GACATAGT ACGCTACT ACTCACTG TGAGTACG CTGCGTAG TAGTCTCC CGAGCGAC ACTACGAC GTCTGCTA GTCTATGA TATAGCGA CGAGAGTT GACATAGT ACGCTACT ACTCACTG TGAGTACG CTGCGTAG TAGTCTCC CGAGCGAC ACTACGAC GTCTGCTA GTCTATGA TATAGCGA CGAGAGTT GACATAGT ACGCTACT ACTCACTG TGAGTACG CTGCGTAG TAGTCTCC CGAGCGAC ACTACGAC GTCTGCTA GTCTATGA TATAGCGA CGAGAGTT GACATAGT ACGCTACT ACTCACTG TGAGTACG CTGCGTAG TAGTCTCC CGAGCGAC ACTACGAC GTCTGCTA GTCTATGA TATAGCGA CGAGAGTT GACATAGT ACGCTACT ACTCACTG TGAGTACG CTGCGTAG TAGTCTCC CGAGCGAC ACTACGAC GTCTGCTA GTCTATGA TATAGCGA CGAGAGTT GACATAGT ACTCACTG TGAGTACG CTGCGTAG TAGTCTCC CGAGCGAC ACTACGAC TATAGCGA TATAGCGA\"\"\", \" \")\n",
    "index2s = split(\"\"\"CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GTCAGATA GTCAGATA GTCAGATA GTCAGATA GTCAGATA GTCAGATA GTCAGATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CTACTATA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA CGTTACTA AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC AGAGTCAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC TACGAGAC ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG ACGTCTCG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG TCGACGAG GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GATCGTGT GTCAGATA\"\"\", \" \")\n",
    "\n",
    "\n",
    "indexes = zip(index1s, index2s) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True number of reads\n",
    "This code generates a set of true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_read_mean = 1e5               # Number of reads\n",
    "sample_read_sd = sample_read_mean*0.5 # Statistical standard deviation (normal dist.)\n",
    "\n",
    "true_sample_reads = Dict([index => (randn()*sample_read_sd + sample_read_mean) for index = indexes]) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate number of reads\n",
    "The code below generates read multiplicities for each index combination, in accordance with what would be expected for a set of mis-assignment probabilities. The simulation logic assumes that the index1 and index2 mis-assignment events are independent.  Wright and Vetsigian found a higher probability than what would be expected for independent variables, but the double mis-assignment rate is still very low -- negligible for practical purposes:\n",
    "\n",
    "|                  |              |\n",
    "|------------------|--------------|\n",
    "|Incorrect i5:     |   0.0604 %   |\n",
    "|Incorrect i7:     |   0.0955 %   |\n",
    "|Incorrect sequence|   0.0872 %   |\n",
    "|Multiple incorrect|   0.0003 %   |\n",
    "\n",
    "It is also notable that the i7 and i5 (respectively, the first and second index) mis-assignment rates are significantly different.\n",
    "\n",
    "We cannot detect sequence misassignments at all using demultiplexing data, and most double misassignments will not be detectable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation parameters (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000604"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index1_misassign_rate = 0.0955 / 100.0\n",
    "index2_misassign_rate = 0.0604 / 100.0\n",
    "## sequence_misassign_rate = 0.0872 / 100.0 ; #Not simulated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Possible indexes in the soup\n",
    "The following arrays the read multiplicity of each single index in the data. I.e. if a sample has a large fraction of the reads, one expect the \"free\" indexes available for mis-assignment to also be relatively larger. Whether this is actually a valid model depends on the mechanism of mis-assigment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index1_mult = Dict()\n",
    "index2_mult = Dict()\n",
    "\n",
    "for ((index1, index2), num_reads) in true_sample_reads\n",
    "    index1_mult[index1] = get(index1_mult, index1, 0) + num_reads\n",
    "    index2_mult[index2] = get(index2_mult, index2, 0) + num_reads\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated number of reads per index sequence\n",
    "This is the main simulation loop, which generates read counts per sample. It's a bit inefficient, could be optimised to not loop over each read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 1 miss rate: 0."
     ]
    }
   ],
   "source": [
    "println(\"Index 1 miss rate: \", index1_misassign_rate)\n",
    "println(\"Index 2 miss rate: \", index2_misassign_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.707091757123878e7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_norm = sum([reads for (seq, reads) = true_sample_reads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim_index_reads = Dict()\n",
    "\n",
    "function weightedrandom(norm, read_dict)\n",
    "    value = rand() * norm\n",
    "    for (seq, num) in read_dict\n",
    "        value -= num\n",
    "        if (value <= 0) \n",
    "            return seq\n",
    "        end\n",
    "    end\n",
    "    throw(ErrorException(\"What happened?\"))\n",
    "end\n",
    "\n",
    "for ((index1, index2), num_reads) in true_sample_reads\n",
    "    for i = 1:num_reads\n",
    "        if rand() < index1_misassign_rate\n",
    "            index1var = weightedrandom(read_norm, index1_mult)\n",
    "        else\n",
    "            index1var = index1\n",
    "        end\n",
    "        if rand() < index2_misassign_rate\n",
    "            index2var = weightedrandom(read_norm, index2_mult)\n",
    "        else\n",
    "            index2var = index2\n",
    "        end\n",
    "        index = (index1var, index2var)\n",
    "        index_reads = get(sim_index_reads, index, 0)\n",
    "        sim_index_reads[index] = index_reads + 1\n",
    "    end\n",
    "end\n",
    "#sim_index_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test case for weightedrandom\n",
    "Does it reproduce the distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000955\n",
      "Index 2 miss rate: 0.000604\n",
      "Original index1 multiplicity (fraction): \n",
      "GCGTATAC: 0.03664993748616886\n",
      "ACTACGAC: 0.049204109810982166\n",
      "GTCTATGA: 0.03920848338765147\n",
      "GACATAGT: 0.041419257290472765\n",
      "AACGCTGA: 0.030519708182145416\n",
      "GATCTACG: 0.054273799656724915\n",
      "CGAGCGAC: 0.04926174300759885\n",
      "GTAACGAG: 0.050681157006630936\n",
      "TATAGCGA: 0.057286564805705195\n",
      "GTCTGCTA: 0.04025738068873764\n",
      "ATAGTACC: 0.042228614303886816\n",
      "TGAGTACG: 0.04057789550814361\n",
      "CGAAGTAT: 0.02130432631361901\n",
      "CGAGAGTT: 0.041782585207710214\n",
      "TCTCTATG: 0.0441979772112745\n",
      "CGTAGCGA: 0.0467550569003659\n",
      "ACGTGCGC: 0.03226695493927716\n",
      "TGCTCGTA: 0.035615062948718586\n",
      "TAGTCTCC: 0.047897459086717734\n",
      "ACGCTACT: 0.03616171528386708\n",
      "CTCGACTT: 0.04858247210655575\n",
      "CTGCGTAG: 0.03726895176830318\n",
      "TAGCAGCT: 0.03507691740485391\n",
      "ACTCACTG: 0.04152186969388792\n",
      "Randomised index1 multiplicity (fraction): \n"
     ]
    }
   ],
   "source": [
    "println(\"Original index1 multiplicity (fraction): \")\n",
    "for (seq, num) = index1_mult\n",
    "    println(seq, \": \", num / read_norm)\n",
    "end\n",
    "# Generate weighted random, see if we get the same\n",
    "wr_num = Dict()\n",
    "N=1e5\n",
    "for i = 0:N\n",
    "    seq = weightedrandom(read_norm, index1_mult)\n",
    "    wr_num[seq] = get(wr_num, seq, 0) + 1\n",
    "end\n",
    "\n",
    "println(\"Randomised index1 multiplicity (fraction): \")\n",
    "for (seq, num) = wr_num\n",
    "    println(seq, \": \", num / N)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for analysis\n",
    "## Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCGTATAC: 0.03619\n",
      "ACTACGAC: 0.04923\n",
      "GTCTATGA: 0.03843\n",
      "GACATAGT: 0.04058\n",
      "CGAGCGAC: 0.0497\n",
      "AACGCTGA: 0.02962\n",
      "GTAACGAG: 0.05138\n",
      "GATCTACG: 0.0556\n",
      "TATAGCGA: 0.05705\n",
      "TGAGTACG: 0.04068\n",
      "GTCTGCTA: 0.03938\n",
      "CGAAGTAT: 0.02168\n",
      "ATAGTACC: 0.04324\n",
      "CGAGAGTT: 0.04123\n",
      "TCTCTATG: 0.04419\n",
      "CGTAGCGA: 0.04694\n",
      "ACGTGCGC: 0.03222\n",
      "TGCTCGTA: 0.03553\n",
      "TAGTCTCC: 0.04838\n",
      "ACGCTACT: 0.03643\n",
      "CTGCGTAG: 0.03696\n",
      "CTCGACTT: 0.04781\n",
      "TAGCAGCT: 0.03486\n",
      "ACTCACTG: 0.0427\n"
     ]
    }
   ],
   "source": [
    "permutations = Set([(i1, i2) for i1 = index1s, i2 = index2s])\n",
    "known = Set(indexes) ;\n",
    "unknown = setdiff(permutations, known)\n",
    "length(unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "Generate metrics that would be available in a real run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Naive formula (wrong)\n",
    "This counts the number of reads assigned to unknown index combinations compared the total number of reads. This ratio is in general less than the total mis-assignment rate, because there is also cross contamination between the actual sample indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17094910"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_sample_reads = sum([sim_index_reads[k] for k = known])\n",
    "sum_unknown_reads = sum([sim_index_reads[k] for k = unknown])\n",
    "total_sum_reads = sum_sample_reads + sum_unknown_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (simple) miss rate: 0"
     ]
    }
   ],
   "source": [
    "mis_id_rate_avg = sum_unknown_reads / (sum_unknown_reads + sum_sample_reads)\n",
    "@printf(\"Average (simple) miss rate: %5.3f %%\\n\", mis_id_rate_avg*100)\n",
    "trueone = (index1_misassign_rate + index2_misassign_rate) / 2.0\n",
    "@printf(\"for comparison: true avg. miss rate: %5.3f %%\\n\", trueone*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per index (end) analysis\n",
    "This repeats the above analysis to see if there is a difference between the first and the second index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".016 %\n",
      "for comparison: true avg. miss rate: 0.078 %\n",
      "Index1 ratio: 0"
     ]
    }
   ],
   "source": [
    "i1known = 0\n",
    "i1unknown = 0\n",
    "for i1 in Set([i1 for (i1, i2)=keys(sim_index_reads)])\n",
    "    i1known   += sum([sim_index_reads[k] for k=filter(x -> x[1] == i1, known)])\n",
    "    i1unknown += reduce(+, 0, [sim_index_reads[k] for k=filter(x -> x[1] == i1, unknown)])\n",
    "end\n",
    "@printf(\"Index1 ratio: %5.3f %%\\n\", i1unknown * 100.0 / (i1known + i1unknown))\n",
    "i2known = 0\n",
    "i2unknown = 0\n",
    "for i2 in Set([i2 for (i1, i2)=keys(sim_index_reads)])\n",
    "    i2known   += sum([sim_index_reads[k] for k=filter(x -> x[2] == i2, known)])\n",
    "    i2unknown += reduce(+, 0, [sim_index_reads[k] for k=filter(x -> x[2] == i2, unknown)])\n",
    "end\n",
    "@printf(\"Index2 ratio: %5.3f %%\\n\", i2unknown * 100.0 / (i2known + i2unknown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis\n",
    "This is a more complex analysis taking into account the level of cross contaminations between samples, which are not observable. This is absolutely necessary to get a reliable result, otherwise only a fraction of the mis-assignment rate is included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second derivation attempt\n",
    "Let $a$ and $b$ represent particular first and second indexes respectively, and $N$ in general represent the number of fragments with a specific combination of indexes.\n",
    "\n",
    "The following is an expression for the number of reads for a given index: \n",
    "\n",
    "$$ R_{a,b} \\approx N^{true}_{a,b}-\\alpha ( \\sum_{i} N^{mis}_{a,b\\to i,b}+\\sum_{i} N^{mis}_{a,b\\to a,i} )\n",
    "   + \\sum_{j} N^{mis}_{j,b\\to a,b} + \\sum_{i} N^{mis}_{a,i\\to a,b}  \\quad (1)$$\n",
    "\n",
    "(ignoring read errors affecting single bases, etc.) The sums are over all possible indexes at the relevant position (first or second), regardless of whether the resulting combinations correspond to a real sample. The sums also include a \"mis-identification\" to the original index. For example, in the first summation term, $\\sum_{i} N^{mis}_{a,b\\to i,b}$, indexes which end up as $a,b$, but through an error, are counted here. This makes the definition of the mis-indentification probability simpler, since it doesn't have to take into account what index replaces the original one. The difference is small on the example data*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *The analysis was first attempted when excluding instances where a fragment was \"mis-identified\" as the correct\n",
    "> index -- when there was a swap, but the replacement happened to be the same as was there originally. The effect\n",
    "> on the results, though, was negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the terms on the right hand side are available as measurements. The first term represents the true number of fragments. The second and third terms (which are multiplied by $\\alpha$) subtract number of times the true index $a,b$ was read as something else, either (second term) due to a wrong first index or (third term) a wrong second index. $\\alpha$ itself is between zero and one and depends on the mode of mis-identification. If additional erroneous fragments are *created*, without destroying any of the original fragments, $\\alpha$ is 0. This is true in the mode postulated by Sinha et al. If fragments instead are changed from the original index to a new one, $\\alpha$ is 1.\n",
    "\n",
    "The final two terms add back the number of times another index was mis-read as $a,b$. The above formula is an approximation because it ignores when *both* indexes were mis-read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precise description of the terms\n",
    " * $ N^{true}_{a,b} $: Number of true fragments with indexes $a$ and $b$ that are detected, but are not necessarily read as such. $N^{true}_{a,b}$ incorporates an overall efficiency factor, which is the probability that a fragment will be detected at all. It only counts detected fragments.\n",
    " * $ N^{mis}_{a,b\\to c,d}$: Number of fragments with index read as $c,d$, but which actually had a true index $a,b$ (where $a$ and $c$, $b$ and $d$, may be equal or different, but at least one of the two pairs is different).\n",
    "\n",
    "These definitions are not directly useful in practice. We can measure $R_{a,b}$ for all combinations of indexes -- known and unknown (to a good approximation). We are, however, after the mis-identification probability,  let's call it $\\gamma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating to the mis-identification probability \"$\\gamma$\"\n",
    "We have to construct a model of how the mis-identification probability relates to $N^{mis}_{a,b\\to c,d}$. We would like to define a $\\gamma$ in a way that is independent of the specific experiment setup used, i.e. the choice of indexes for each sample, or the relative number of reads for each sample. It should only depend on the particular sample prep and/or sequencing technology used (and potentially global conditions such as the error rate). There is in general a separate mis-ID probability for the first and the second index, $\\gamma_1$ and $\\gamma_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first concentrate on the specific case of a mis-identification of the second index, however this could be reversed in general. We can postulate that the number of mis-identified fragments originating from a particular index pair $a,j$ (i.e. first index $a$ and second index $j$) is proportional to the number of true such fragments:\n",
    "$$ N^{mis}_{a,j\\to a,k} = \\gamma_2 N^{true}_{a,j} f(k)\\; ,$$\n",
    "where $f(k)$ is an unspecified function of the \"replacement\" index $k$. For mis-identification of the first index:\n",
    "$$ N^{mis}_{j,b\\to k,b} = \\gamma_1 N^{true}_{j,b} f'(k)$$\n",
    "($f'(k)$ is the corresponding function for the first index)\n",
    "\n",
    "Studies show that index read mis-assignments are not primarily caused by random read errors of single bases. Instead, there will exist a genuine index $k$ somewhere which somehow gets combined with $a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional dependence on the \"target\" index\n",
    "In a model where true fragments with index $x,k$ (any first index) are consumed in order to convert $a,j$ to $a,k$, the function $f(k)$ would depend on the number of available such fragments, i.e.,\n",
    "$$ f(k) = \\frac{1}{N_{tot}} \\sum_i N_{i,k}^{true} \\; ,$$\n",
    "where $N_{tot}$ is the total number of fragments detected.\n",
    "\n",
    "The study of Sinha et al. give us reason to believe that the probability to create new fragments with index $k$ depends on the amount of free index primer with the index $k$ left in the pool at the time of cluster generation. Apart from the obvious extra variables, the concentration of each index primer, it is also not given that the factorisation of $N^{mis}_{a,j\\to a,k}$ above holds when the index primer is the limiting element. Nevertheless, we move ahead with this formula, since this also happens to be the model used in the simulation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving for $\\gamma$\n",
    "We will show later how $\\gamma$ can be a useful quantity to describe the scale of the mis-assignment problem, but we will first work out its relation to the observable quantities $R_{a,b}$.\n",
    "\n",
    "In order to estimate $\\gamma$, there needs to be an index combination $a,b$ which does not correspond to any sample -- a first and second index which exists in the pool, but not as a combination. Then we have $N^{true}_{a,b}=0$. Then Eq. 1 reduces to:\n",
    "$$ R_{a,b} = -\\alpha \\left( \\sum_{i} N^{mis}_{a,b\\to i,b}+\\sum_{i} N^{mis}_{a,b\\to a,i} \\right)\n",
    "    + \\sum_{i} N^{mis}_{i,b\\to a,b} + \\sum_{i} N^{mis}_{a,i\\to a,b}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding the mis-identification terms leads to: \n",
    "$$ R_{a,b} = -\\alpha \\left( \\sum_{i} (\\frac{\\gamma_1}{N_{tot}}  N_{a,b}^{true}\\sum_m N_{m,i}^{true})\n",
    "        + \\sum_{i}  (\\frac{\\gamma_2}{N_{tot}} N_{a,b}^{true}\\sum_m N_{i,m}^{true}) \\right) \\\\\n",
    "        + \\sum_{i}  (\\frac{\\gamma_1}{N_{tot}} N_{a,i}^{true}\\sum_m N_{m,b}^{true})\n",
    "        + \\sum_{i}  (\\frac{\\gamma_2}{N_{tot}} N_{i,b}^{true}\\sum_m N_{a,m}^{true}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two terms also vanish, because $N^{true}_{a,b}=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ R_{a,b} = \\sum_{i}  (\\frac{\\gamma_1}{N_{tot}} N_{a,i}^{true}\\sum_m N_{m,b}^{true})\n",
    "           + \\sum_{i}  (\\frac{\\gamma_2}{N_{tot}} N_{i,b}^{true}\\sum_m N_{a,m}^{true}) \\\\\n",
    "           $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sums can be collected \n",
    "$$ R_{a,b} = \\frac{\\gamma_1}{N_{tot}} \\sum_{i} \\sum_m N_{a,i}^{true} N_{m,b}^{true}\n",
    "           + \\frac{\\gamma_2}{N_{tot}} \\sum_{i} \\sum_m N_{i,b}^{true} N_{a,m}^{true} \\; .\n",
    "           $$\n",
    "This is as far as we get with algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An approximate expression related to observable quantities\n",
    "To first order in $\\gamma$, $R_{i,j} = N_{i,j}^{true}$. Assuming the mis-identification probability is small, we can replace $N^{true}$ in the above expression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "   R_{a,b} = \\frac{\\gamma_1}{N_{tot}} \\sum_{i} \\sum_m R_{a,i} R_{m,b}\n",
    "           + \\frac{\\gamma_2}{N_{tot}} \\sum_{i} \\sum_m R_{i,b} R_{a,m} \\; . \\quad (2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a,b$ is still assumed to be a specific index combination with zero true reads. For a moment we can assume that the mis-ID probabilities are equal (as well as the constants $C$), $\\gamma_1'=\\gamma_2'\\equiv \\gamma'$, and solve Eq. 2 for $\\gamma'$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\frac{R_{a,b}N_{tot}}{\\sum_{i} \\sum_m R_{a,i} R_{m,b} + \\sum_{i} \\sum_m R_{i,b} R_{a,m}} = \\gamma\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".016 %\n",
      "Index2 ratio: 0.016 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Cloning cache of Plots from git://github.com/JuliaPlots/Plots.jl.git\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: failed process: Process(`git clone -q --mirror git://github.com/JuliaPlots/Plots.jl.git /home/fa2k/.julia/v0.4/.cache/Plots`, ProcessSignaled(2)) [0]\n in pipeline_error at ./process.jl:555\nwhile loading In[13], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: failed process: Process(`git clone -q --mirror git://github.com/JuliaPlots/Plots.jl.git /home/fa2k/.julia/v0.4/.cache/Plots`, ProcessSignaled(2)) [0]\n in pipeline_error at ./process.jl:555\nwhile loading In[13], in expression starting on line 1",
      "",
      " [inlined code] from ./task.jl:422",
      " in add at ./pkg/entry.jl:64"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"Plots\")\n",
    "using Plots\n",
    "plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loops over all $R_{a,b}$ and computes the terms above. The arrays will be used in subsequent code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean gamma is: 0"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: histogram not defined\nwhile loading In[14], in expression starting on line 22",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: histogram not defined\nwhile loading In[14], in expression starting on line 22",
      "",
      " in anonymous at ./no file:4294967295"
     ]
    }
   ],
   "source": [
    "gammas = Float64[]\n",
    "R_a_bs = Float64[]\n",
    "for index = unknown\n",
    "    a, b = index\n",
    "    R_a_b = sim_index_reads[index]\n",
    "    push!(R_a_bs, R_a_b)\n",
    "    term1_sum =  0.0\n",
    "    for (aa, j) = keys(sim_index_reads)\n",
    "        for (m, bb) = filter(i1_i2 -> i1_i2[2] == b, keys(sim_index_reads))\n",
    "            term1_sum += sim_index_reads[(a,j)] * sim_index_reads[(m,b)]\n",
    "        end\n",
    "    end\n",
    "    term2_sum =  0.0\n",
    "    for (i, bb) = keys(sim_index_reads)\n",
    "        for (aa, m) = filter(i1_i2 -> i1_i2[1] == a, keys(sim_index_reads))\n",
    "            term2_sum += sim_index_reads[(i,b)] * sim_index_reads[(a,m)]\n",
    "        end\n",
    "    end\n",
    "    push!(gammas, R_a_b * total_sum_reads / (term1_sum + term2_sum))\n",
    "end\n",
    "@printf(\"Mean gamma is: %5.3f %%\\n\", mean([gamma*100 for gamma=gammas]))\n",
    "histogram([gamma*100.0 for gamma=gammas], bins=10, xlab=\"#gamma (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the average $\\gamma$ in percent. This is pretty close to the true values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0955"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index1_misassign_rate * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0604"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2_misassign_rate * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but significantly off target. This may be explained by the fact the the simulated mis-assignments allow the return to the same index. E.g. if we decide in the simulation that index1 is to be replaced, we pick a new index1, which may in fact be the same as the one we started with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more precision, we attempt to reconstruct both probabilities using linear regression. We can rewrite Eq. 2 in a form which is acceptable for Julia's linear solver, namely $bx+a=y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "   \\gamma_1 \\sum_{i} \\sum_m R_{a,i} R_{m,b}\n",
    "           +\\gamma_2 \\sum_{i} \\sum_m R_{i,b} R_{a,m} = N_{tot} R_{a,b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "   \\gamma_1 \\sum_{i} \\sum_m R_{a,i} R_{m,b}\n",
    "           - N_{tot} R_{a,b} = -\\gamma_2 \\sum_{i} \\sum_m R_{i,b} R_{a,m}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "   \\gamma_1 \\frac{\\sum_{i} \\sum_m R_{a,i} R_{m,b}}{N_{tot} R_{a,b}}\n",
    "           - 1 =-\\frac{\\gamma_2 \\sum_{i} \\sum_m R_{i,b} R_{a,m}} {N_{tot} R_{a,b}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "   \\frac{\\gamma_1}{\\gamma_2} \\frac{\\sum_{i} \\sum_m R_{a,i} R_{m,b}}{N_{tot} R_{a,b}}\n",
    "           - \\frac{1}{\\gamma_2} =-\\frac{\\sum_{i} \\sum_m R_{i,b} R_{a,m}} {N_{tot} R_{a,b}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use linear regression to solve for $\\gamma_1/\\gamma_2$ and $1/\\gamma_2$. The loop above has been adjusted to compute $x$ and $y$ values instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma1: 2"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Not plotting today\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".6764399223718335e12\n",
      "gamma2: -2.6764399223718325e12\n"
     ]
    }
   ],
   "source": [
    "xs = Float64[]\n",
    "ys = Float64[]\n",
    "for index = unknown\n",
    "    a, b = index\n",
    "    R_a_b = sim_index_reads[index]\n",
    "    term1_sum =  0.0\n",
    "    for (aa, j) = filter(i1_i2 -> i1_i2[1] == a, keys(sim_index_reads))\n",
    "        for (m, bb) = filter(i1_i2 -> i1_i2[2] == b, keys(sim_index_reads))\n",
    "            term1_sum += sim_index_reads[(a,j)] * sim_index_reads[(m,b)]\n",
    "        end\n",
    "    end\n",
    "    term2_sum =  0.0\n",
    "    for (i, bb) = filter(i1_i2 -> i1_i2[2] == b, keys(sim_index_reads))\n",
    "        for (aa, m) = filter(i1_i2 -> i1_i2[1] == a, keys(sim_index_reads))\n",
    "            term2_sum += sim_index_reads[(i,b)] * sim_index_reads[(a,m)]\n",
    "        end\n",
    "    end\n",
    "    push!(xs, term1_sum / (total_sum_reads * R_a_b))\n",
    "    push!(ys, -term2_sum / (total_sum_reads * R_a_b))\n",
    "end\n",
    "a, b = linreg(xs, ys)\n",
    "gamma2 = -1/a\n",
    "gamma1 = b * gamma2\n",
    "println(\"gamma1: \", gamma1)\n",
    "println(\"gamma2: \", gamma2)\n",
    "\n",
    "line = [a+b*i for i in xs]\n",
    "#plot([ys line], xs, marker = (:hexagon, 20, 0.6, stroke(3, 0.2, :black, :dot)))\n",
    "\"Not plotting today\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each point is an unknown index. The units of the $x$ and $y$ axes are dimensionless. The variables in the linear equation all have the form of (number of fragments squared) / (number of fragments squared). This form comes from the fact that $R_{a,b}$ depends on a product of fragment counts -- both the \"source\" and the \"replacement\".\n",
    "\n",
    "From the plot it is clear that the gamma values fall exactly on a line. This is not expected -- randomness is introduced in the mis-identification rate and the fraction of each index in the ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion back to a probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.4.7",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
